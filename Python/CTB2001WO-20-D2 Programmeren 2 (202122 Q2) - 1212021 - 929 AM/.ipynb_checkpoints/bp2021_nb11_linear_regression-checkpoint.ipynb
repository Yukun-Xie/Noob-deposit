{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://raw.githubusercontent.com/mbakker7/exploratory_computing_with_python/master/tudelft_logo.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Exploratory Computing with Python\n",
    "*Developed by Mark Bakker and David Steffelbauer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 11: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook, we learn how to fit a straight line to a set of data; fitting a model to data is also called regression analysis. We discuss how the best parameters are computed and how the goodness of fit can be quantified. Next, we apply linear regression analysis to real data of a water distribution system of a small town to try to detect a leak. At the end of the Notebook, we try to compute confidence intervals of our fitted lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root mean squared error\n",
    "One way to quantify the fit between data and a model is to compute the root mean squared error. The error is defined as the difference between the observed value and the modeled value. Another term for the error is the residual. The error of data point $i$ is written as \n",
    "\n",
    "$$\\varepsilon_i = y_i - \\hat{y}_i$$ \n",
    "\n",
    "where $y_i$ is the measured (observed) value and $\\hat{y}_i$ is the fitted value. The sum of squared errors $S$ is\n",
    "\n",
    "$$S = \\sum_{i=1}^N{\\varepsilon_i^2}$$ \n",
    "\n",
    "where $N$ is the number of observations. Finally, the root mean squared error $E$ is computed as\n",
    "\n",
    "$$E=\\sqrt{\\frac{1}{N}S}=\\sqrt{\\frac{1}{N}\\sum_{i=1}^N{\\varepsilon_i^2}}$$\n",
    "\n",
    "The root mean squared error is an estimate of the goodness of fit and can be computed for any model and any dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1. Fit a straight line\n",
    "The file `xydatafit.dat` contains $x$ values (first row) and $y$ values (second row). Fit a straight line $y=ax+b$ through the data using the `linregress` function of `scipy.stats`. Note that the `linregress` function returns 3 other values besides the slope and intercept (use `linregress?` to find out what they are; more on these 3 additional values later on in this Notebook). Plot the data (with markers) and add the fitted straight line. Add 'x' and 'y' as labels along the axes. Add a legend and specify the legend for each plot using the `label` keyword argument in the `plot` function. Add the root mean squared error as a title to the graph (use `f-string` formatting with 3 significant digits). Print the optimal values for the slope and intercept of the straight line to the screen (using 3 significant digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope = -0.029, intercept = 0.397\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import linregress as lr\n",
    "a = np.loadtxt(\"xydatafit.dat\")\n",
    "b = lr(a[0], a[1])\n",
    "plt.plot(a[0], a[1], \".\", label = \"data\")\n",
    "x = np.linspace(1, 10, 100)\n",
    "y = b[0] * x + b[1]\n",
    "plt.plot(x, y, label = \"Regression line\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "ybar = b[0] * a[0] + b[1]\n",
    "MSE_root = np.square(np.subtract(a[1],ybar)).mean() ** 0.5\n",
    "plt.title(f\"The root mean squared error is {MSE_root:.3f}\")\n",
    "plt.legend()\n",
    "print(f\"slope = {b[0]:.3f}, intercept = {b[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares\n",
    "In the exercise above, the *optimal* or *best* parameters were obtained with the `linregress` method. But how did `linregress` do that? Or maybe a more fundamental question: 'What is *optimal*?' or 'What is *best*?'. In this Notebook, we define *best* as the parameter set that minimizes the sum of the squared errors $S$ (so it also minimizes the root mean squared error $E$). Such an optimization approach is referred to as a *least squares* approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The straight line is written as $y=ax+b$, where $a$ is the slope of the line and $b$ is the intercept (it is the value of $y$ for $x=0$). In the code cell below, we write a function that takes four input arguments: an array of observed $x$ values, an array of corresponding $y$ values, the slope $a$, and the intercept $b$. The function returns the sum of squared errors $S$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-68b2870b53bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0msse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mydata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xdata' is not defined"
     ]
    }
   ],
   "source": [
    "def sse(a, b, x=xdata, y=ydata):\n",
    "    error = y - (a * x + b)\n",
    "    return np.sum(error ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different values of $a$ and $b$ give different values for the sum of squared errors. The sum of squared errors is larger for $a=-0.05$ and $b=0.3$ than for $a=-0.02$ and $b=0.5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-428d76fe6f6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'sse of a=-0.05, b=0.3: {sse(a=-0.05, b=0.3)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'sse of a=-0.02, b=0.5: {sse(a=-0.02, b=0.5)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sse' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'sse of a=-0.05, b=0.3: {sse(a=-0.05, b=0.3)}')\n",
    "print(f'sse of a=-0.02, b=0.5: {sse(a=-0.02, b=0.5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do is compute the `sse` function for a larger number of $a$ and $b$ values. If we do that on a grid, we can create contours of the `sse` function. The `sse` function is constant along any contour. A contour map of the `sse` function is similar to an elevation map. The goal is now to find the combination of $a$ and $b$ that gives the smallest value of the sum of squared errors. In the graph below, you can see that the smallest value of `sse` is obtained at $a\\approx -0.03$, $b\\approx 0.4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.meshgrid(np.linspace(-0.05, -0.02, 50), np.linspace(0.3, 0.5, 50))\n",
    "ssevec = np.vectorize(sse)\n",
    "z = ssevec(a, b)\n",
    "plt.contour(a, b, z, 100)\n",
    "plt.colorbar()\n",
    "plt.xlabel('a')\n",
    "plt.ylabel('b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we minimize the sum of squared errors? As usual, we find the minimum of a function by taking the derivative and setting it to zero. For a straight line, this can be done exactly. We won't derive the equations here (you will learn them in CTB3310). For more complicated models, the minimum is found with a search algorithm, as we will do in the next notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The correlation coefficient and $p$-value. \n",
    "The `linregress` function returns 5 values. Besides the slope and intercept, these are somewhat cryptically defined as the correlation coefficient, the $p$-value, and the standard error (the last one is not explained in this Notebook). Each of these three values is a quantification of the goodness of fit. Let's first discuss the correlation coefficient.\n",
    "\n",
    "The square of the correlation coefficient $r$ is the *r-squared value* and is defined as\n",
    "\n",
    "$$r^2 = 1 - \\sum{(y_i - \\hat{y}_i)^2} \\left/ \\sum{(y_i - \\bar{y})^2} \\right. $$\n",
    "\n",
    "where $y_i$ is the $y$ value of data point $i$, while $\\hat{y}_i$ is the fitted value at data point $i$. If the model goes exactly through the data (a perfect fit), then $y_i - \\hat{y}_i=0$ for every $i$, and $r^2=1$. If the model doesn't do any better than simply the mean of $y$, then the  $r^2$ is zero. A value of $r^2$ close to 1 is generally a good thing, but it is not possible to say anything definitive about the goodness of fit by just reporting the $r^2$ value (although many people do)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meaning of the $p$-value\n",
    "The fourth return value of the `linregress` function is the $p$-value. The $p$-value is related to the question whether the estimated slope is significantly different from zero. When the slope is significantly different from zero, you can state that there is a linear relationship between the two variables. The $p$-value is related to the question whether the estimated absolute value of the slope is significantly different from zero when you perform a statistical test, a $t$-test to be precise. When the $p$-value is less than 0.05, this means that when you perform a two-sided $t$-test you can reject the null hypothesis that the slope is zero in favor of the alternative hypothesis that the slope is not zero. In layman terms: it means that there is less than 5% chance that the slope is zero and more than 95% chance that the slope is not zero. Or even simpler: the slope is significantly different from zero. Obviously, for the current data, there is a high probability that the slope is significantly different from zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2. Getting a value of $p<0.05$ by chance\n",
    "Write a function that generates 100 $x$ values randomly from a uniform distribution between 0 and 1 and 100 $y$ values randomly from a uniform distribution between 0 and 1. Use the `np.random.rand` function to generate the random numbers. Next, fit a straight line using `linregress`. The function takes no input arguments and returns the fitted slope, the fitted intercept, the $p$-value, the generated $x$ values, and the generated $y$ values. \n",
    "\n",
    "Next, perform the following experiment: Call the function you wrote 1000 times and count how many times $p<0.05$, which means the slope of the fitted line is significantly different from zero even though the data is random. Print the number of times $p<0.05$ to the screen. As you will see, you will get approximately 50 out of the 1000 experiments where a line is fitted with a $p$-value smaller than 0.05 just by chance. That means that 5% of the time you will incorrectly conclude that there is a linear relationship between $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3. Getting a value of $p<0.05$ by chance contiued\n",
    "Call the function your wrote in Exercise 2 inside a loop and break out of the loop when you find a dataset where $p<0.02$. Make a graph for this dataset. Plot the dataset with dots and the fitted line with a line. Add labels and a legend. Can you see a linear relationship between $x$ and $y$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real data - Minimum Night Flow analysis\n",
    "The csv file `inflow_data.csv` contains real data of inflow measurements in a water distribution system from a small town (approx 2000 inhabitants) in Austria in February 2017. Inflow in a system is an important measure since it represents the total water consumption of all households in a certain area. It also contains data of water losses. The first column of the file contains the date and time when the measurements were taken, and the second column contains the inflow measurements in liters per second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4. Inflow data\n",
    "Load the inflow data from the file `inflow_data.csv` using `pandas` and make sure the date can be used as an index. Make a graph of the inflow data for the entire month using a figure size of `(10,5)`. Add labels on the axes. Next, in a separate graph, make a graph of the inflow data for February 1, 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first figure, you see that the water consumption follows a certain pattern with repeating elements with a frequency of 24 hours. On the third day, we can see a large spike in the consumption. During the nighttime on the 6th of February, the flow seems to be larger compared to the other nights. This can also be seen on the 24th and the 26th. \n",
    "\n",
    "The water consumption follows the daily routine of the inhabitants in a zone. From the second figure, you can see that around 6:00 in the morning, people wake up and use lots of water water (e.g. to shower, go to the toilet or prepare breakfast), resulting in the so-called morning peak. After that, some people will go to work and leave the area, so that the water consumption decreases. In the evening, people return to their homes, and more water is used resulting in a second peak. For example,  people prepare dinner, take showers, do the laundry or dishes, use the toilet and brush their teeth before they go to bed. While people are sleeping, they do not use water. This can be seen between 2:00 and 4:00 in the night, which are called the minimum night flow (MNF) hours.\n",
    "\n",
    "The MNF hours are very important for water utilities. Since the consumption is minimal, the pressure in the system is high. Leakage from water distribution systems is pressure dependent: The higher the pressure, the more water is lost through leakage. Hence, leaks can be detected easiest during the MNF hours. In addition, fluctuations in the inflow measurements is minimal during the MNF hours. Let's have a closer look at the water consumption during the MNF hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5. Minimum Night Flow (MNF)\n",
    "Compute the mean inflow between the MNF hours (from 2:00 till 4:00) for each day (so 28 values). Use the `.between_time` function of `pandas` to select all the inflows between 2:00 and 4:00 and store the values in a new `DataFrame`. Next, use `resample` to compute the mean MNF value for each day.  Make a bar graph of the mean MNF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note again the higher consumption on February the 6th, 24th and 26th (and the 28th). Water utilities analyze the MNF to find leaks in their system. If the consumption during MNF shows a clear peak, there may be a leak in the system, and the utility company may send out a team to find and repair the leak. \n",
    "\n",
    "Not all leaks result in a sudden increase in water consumption. Some leaks grow slowly over time. These leaks are harder to find: the MNF increases slowly over time. This is where linear regression analysis may be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6. A simple $p$-value based leak detector\n",
    "Write a function that takes two input arguments: an array with day numbers and a corresponding array with the MNF for those days. The function performs a linear regression and creates a graph showing the data with markers and the fitted line. The title of the graph is the $p$-value and the text 'there is a leak!' when the $p$-value of the linear regression is smaller than 0.05 and 'there is probably no leak' otherwise. The function returns nothing. Use the MNF data computed in the previous exercise. Call your function with the first 14 days of data and after that with the last 14 days of data (so you end up with two separate graphs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
